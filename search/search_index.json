{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#welcome-to-omnibenchmark-documentation","title":"Welcome to Omnibenchmark documentation","text":"<p>Omnibenchmark is a benchmark project that aims to provide community-driven, modular, extensible and always up-to-date benchmarks.</p> <p>It is based on the Renku project, an open and collaborative data analysis platform.</p> <p>The framework connects data, methods and metrics repositories (a.k.a. modules), that can be flexibly extended by any community member.</p> <p>If you are interested in contributing a new method, dataset or metric, follow the documentation from the <code>Getting started</code> section, where you can learn more about how omnibenchmark works and how to extend it with a new module.</p> <p>If you are interested in exploring one of the existing benchmarks and the latest results, you can directly jump to the results of our evaluations in the <code>Output</code> section.</p> <p></p>"},{"location":"01_landing/","title":"Motivation","text":"<p>Benchmarking is a critical step for the development of bioinformatic methods and provides important insights for their application.</p> <p>The current benchmarking scheme has many limitations:</p> <ul> <li> <p>It is a snapshot of the available methods at a certain time point and often already outdated when published.</p> </li> <li> <p>Comparison of benchmarks is challenging: different procedures, different datasets, different evaluation criteria, etc.</p> </li> <li> <p>All of the above can lead to different conclusions among benchmarks made at different time points or at different groups.</p> </li> </ul>"},{"location":"01_landing/#concept","title":"Concept","text":"<p>Omnibenchmark is a modular and extensible framework based on a free open-source analytic platform, Renku, to offer a continuous and open community benchmarking system.</p> <p>The framework consists of data, method and metric repositories (or \u201cmodules\u201d) that share data components and are tracked via a knowledge graph from the Renku system. The results can be displayed in an interactive dashboard to be openly explored by anyone looking for recommendations of tools. New data, methods or metrics can be added by the community to extend the benchmark.</p> <p>Some key features of our benchmarking framework:</p> <ul> <li> <p>Periodical updates of the benchmark to provide up-to-date results</p> </li> <li> <p>Easy extensibility through templates for data, methods or metrics</p> </li> <li> <p>Following FAIR principles by using software containers, an integration with Gitlab and full provenance tracking (inputs, workflows and generated files)</p> </li> <li> <p>Flexibility to work with different benchmarking structures, topics and programming languages.</p> </li> </ul>"},{"location":"01_landing/#prototype","title":"Prototype","text":"<p>We are currently building a prototype for community-based benchmarking of single cell batch correction methods. The research in single-cell is a perfect use-case, where more than 1000 tools have been developed in only a few years (see  for e.g. scrna-tools)  and where the benchmarking efforts are often not coordinated , not extendable and not reproducible.</p>"},{"location":"about/","title":"Indetonsusque loca est","text":""},{"location":"about/#calidi-seu","title":"Calidi seu","text":"<p>Lorem markdownum, nunc aret fragorem sorori, dea antemnas sinat, Philippi, auctor, adfixa! Aere Venulus, me dubitare fronte peregrina feruntur et iussit resolvite? Nocte cervix truncos recessit, apri his fatemur timori Tantalis, et haec metum clipeum.</p>"},{"location":"about/#non-nec-comitatur-palmae-redolentia-tamen-aut","title":"Non nec comitatur palmae redolentia tamen aut","text":"<p>Queri voce oblivia subito, ex timentes utque: ferox diligitur candidus veros. Vixque nostri nec est inpulsos cupiuntque in color, terris mihi oves gloria comae aut Salmaci? Inde causa tantos toro: non imo ab atque; abstrahit intexere. Saxum de totaque certe fecit nive triplici, si nam cum meo feroci diu culpa canibusve magna.</p>"},{"location":"about/#sine-fatemur-versa-perdite-est-isto-trabes","title":"Sine fatemur versa perdite est isto trabes","text":"<p>Facundia dixit huic nefasque decimo suae dixit non. Rectum dumque acies qua, dixerat, fitque, tali tuum bellica!</p> <p>Belua poenaededidit lecti ferunt fatale mutentur sacerdos alta, ab nec dis. Nam et Dianae vitare Numam, esse cum! Qui et Lycaon omnes: dixi oblita?</p>"},{"location":"about/#olorinis-summum","title":"Olorinis summum","text":"<p>Colunt breviter Saturnia Threicius motasse aestus tibi obliquo maesto caeruleaeque alti, qui cum vias tenet pelagi noctem? Uni axe ossa, laesi, sed ducere tantum caducas atricolor vicinia pervia!</p> <ol> <li>Veteris abit iussae ictus cohaesit</li> <li>Alter diro Scyllae suoque superat nullos Cumarum</li> <li>Plangoris prohibebant deferre capillis</li> <li>Ponit ante nemus</li> <li>Ait parte quem Hymenaeus</li> </ol> <p>Referrem per mihi spiritus, praecipites Somni quoque, oppositoque. Cum occuluit Iovem ire: pulcherrime neque frondes vultumque anili, sic habet sustulerat quam ad nymphae Haemonias ostendit! Lapis quaerens potitur carpitur iam, terra ima Autolycus Aegaeo, Tegeaea et! Etiam nitidum transire Bromiumque vestrum; thalami enim lateri profundum aconita nec!</p>"},{"location":"old_index/","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"old_index/#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"old_index/#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"advanced/01_utils/","title":"Utils","text":"<p>some text. </p>"},{"location":"advanced/02_orchestrator/","title":"CI/CD Orchestrator.","text":"<p>Some text. </p>"},{"location":"advanced/03_components/","title":"Components dashboard.","text":"<p>Some text. </p>"},{"location":"how_to/","title":"Index","text":"<p>.. _How_to_guides:</p>"},{"location":"how_to/#how-to-guides","title":"How-to Guides","text":"<p>All relevant information about a module are summarized in the OmniObject class. </p> <p>The following sections will explain how to build an OmniObject, use its class functions to generate and update dataset and workflows and how to modify it for more sepcific use cases:</p> <p>.. toctree::    :glob:    :maxdepth: 1    :includehidden:</p> <p>how_to/*</p>"},{"location":"how_to/01_build_object/","title":"Build object","text":"<p>(section-build-yaml)=</p>"},{"location":"how_to/01_build_object/#build-an-omniobject-from-yaml","title":"Build an OmniObject from yaml","text":"<p>All relevant information on how to run a specific module are stored as {ref}<code>OmniObject &lt;section-omniobject&gt;</code>. The most convenient way to generate an instance of an <code>OmniObject</code> is to build it from a <code>config.yaml</code> file using the <code>get_omni_object_from_yaml()</code> function:</p> <pre><code>## modules\nfrom omnibenchmark.utils.build_omni_object import get_omni_object_from_yaml\n\n## Load object\nomni_obj = get_omni_object_from_yaml('src/config.yaml')\n\n</code></pre>"},{"location":"how_to/02_create_dataset/","title":"Create dataset","text":"<p>(section-datasets)=</p>"},{"location":"how_to/02_create_dataset/#datasets","title":"Datasets","text":""},{"location":"how_to/02_create_dataset/#generate-datasets","title":"Generate Datasets","text":""},{"location":"how_to/02_create_dataset/#add-files","title":"Add files","text":""},{"location":"how_to/02_create_dataset/#update-datasets","title":"Update datasets","text":""},{"location":"how_to/03_generate_workflow/","title":"03 generate workflow","text":"<p>(section-workflow)=</p>"},{"location":"how_to/03_generate_workflow/#generate-and-update-workflows","title":"Generate and update workflows","text":""},{"location":"how_to/04_update_object/","title":"04 update object","text":"<p>(section-update)=</p>"},{"location":"how_to/04_update_object/#update-omniobject","title":"Update OmniObject","text":""},{"location":"how_to/05_filter/","title":"05 filter","text":"<p>(section-filter)=</p>"},{"location":"how_to/05_filter/#filter-omniobject","title":"Filter OmniObject","text":""},{"location":"how_to/05_filter/#filter-input-datasets","title":"Filter input datasets","text":""},{"location":"how_to/05_filter/#filter-parameter","title":"Filter parameter","text":""},{"location":"how_to/05_filter/#parameter-limits","title":"Parameter limits","text":""},{"location":"how_to/05_filter/#parameter-values","title":"Parameter values","text":""},{"location":"how_to/05_filter/#parameter-combinations","title":"Parameter combinations","text":""},{"location":"how_to/05_filter/#input-dataset-specific-parameter-combinations","title":"Input dataset specific parameter combinations","text":""},{"location":"output/01_prototype_batch/","title":"Batch correction","text":"<p>Results of our protype, evaluating: </p> <ul> <li> <p>two datasets</p> </li> <li> <p>two batch-correction methods</p> </li> <li> <p>two different metrics. </p> </li> </ul> <p>(http://imlspenticton.uzh.ch:3840/bettr_test/)[http://imlspenticton.uzh.ch:3840/bettr_test/]</p>"},{"location":"start/","title":"Index","text":""},{"location":"start/#getting-started","title":"Getting started","text":"<p>The main advantage of the Omnibenchmark project is its modularity: components can be easily added to the data, methods or metrics modules. </p> <p>The following sections will explain how to bring such extensions. If you are interested in adding modules to omnibenchmark, it is required that:</p> <ol> <li> <p>you have a valid account to access <code>Renku &lt;https://renkulab.io/&gt;</code>_ </p> </li> <li> <p>you have a script for you data, method or metric.</p> </li> </ol> <p>.. toctree::    :glob:    :maxdepth: 2    :includehidden:</p> <p>start/*</p>"},{"location":"start/01_data_module/","title":"Data modules","text":"<p>Data modules are modules that define input datasets and bundle them into a renku dataset, that can be imported by other projects. Benchmark specific requirements like file formats, types and prefixes can be checked at the omnibenchmark webside. Most modules contain 3 main files:</p>"},{"location":"start/01_data_module/#1-the-configyaml-file","title":"1. The config.yaml file","text":"<p>All information about the module are specified in the {ref}<code>config.yaml file &lt;section-config&gt;</code>:</p> <pre><code>---\ndata:\n    name: \"dataset-name\"\n    title: \"dataset title\"\n    description: \"A new dataset module for omnibenchmark\"\n    keywords: [\"MODULE_KEY\"]\nscript: \"path/to/module_script\"\noutputs:\n    files:\n        data_file1: \n            end: \"FILE1_END\"\n        data_file2:\n            end: \"FILE2_END\"\n        data_file3:\n            end: \"FILE3_END\"\nbenchmark_name: \"OMNIBENCHMARK_TYPE\"\n</code></pre> <p>Entries in capital letters depend on the specifications at the omnibenchmark webside.</p>"},{"location":"start/01_data_module/#2-the-run_workflowpy-file","title":"2. The run_workflow.py file","text":"<p>This file is to generate, run and update the modules dataset and workflow. A most basic script to do so looks like this:</p> <pre><code># Load modules\nfrom omnibenchmark.utils.build_omni_object import get_omni_object_from_yaml\nfrom omnibenchmark.renku_commands.general import renku_save\n\n# Build an OmniObject from the config.yaml file\nomni_obj = get_omni_object_from_yaml('src/config.yaml')\n\n# Create the output dataset\nomni_obj.create_dataset()\nrenku_save()\n\n## Run and update the workflow\nomni_obj.run_renku()\nrenku_save()\n\n## Add files to output dataset\nomni_obj.update_result_dataset()\nrenku_save()\n</code></pre>"},{"location":"start/01_data_module/#3-the-module-script","title":"3. The module script","text":"<p>This is the script to load the dataset and to convert its files into the expected format. Omnibenchmark accepts any kind of script and its maintenance and content is up to the module author. Omnibenchmark calls this script from the command line. If you use another language than R, Python, Julia or bash, specify the interpreter to use in the corresponding field of the {ref}<code>config.yaml file &lt;section-config&gt;</code> file.</p> <p>:::note All input and output files and if applicable parameter need to be parsed from the command line in the format: <code>--ARGUMENT_NAME ARGUMENT_VALUE</code> :::</p> <p>In Python argparse can be used to parse command arguments like this:</p> <pre><code># Load module\nimport argparse\n\n# Get command line arguments and store them in args\nparser=argparse.ArgumentParser()\nparser.add_argument('--argument_name', help='Description of the argument')\nargs=parser.parse_args()\n\n# Call the argument\narg1 = args.argument_name\n\n</code></pre> <p>In R we recommend to use the optparse package:</p> <pre><code># Load package\nlibrary(optparse)\n\n# Get list with command line arguments by name\noption_list = list(\n    make_option(c(\"--argument_name\"), type=\"character\", default=NULL, \n              help=\"Description of the argument\", metavar=\"character\")\n); \n\nopt_parser = OptionParser(option_list=option_list);\nopt = parse_args(opt_parser);\n\n# An useful error if the argument is missing\nif (is.null(opt$argument_name)){\n  print_help(opt_parser)\n  stop(\"Argument_name needs to be specified, but is missing.n\", call.=FALSE)\n}\n\n# Call the argument\narg1 &lt;- opt$argument_name\n</code></pre>"}]}